{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-SWWk9sLLfr",
        "outputId": "ee009f31-a283-4520-a899-d8e4b87141d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "zip_path = \"/content/drive/MyDrive/ML/data.zip\"\n",
        "unzip_path = \"/content/data\"\n",
        "if not os.path.exists(unzip_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(unzip_path)"
      ],
      "metadata": {
        "id": "iwvqxWV8MTQi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import timm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import precision_score, f1_score, recall_score, confusion_matrix\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import datasets"
      ],
      "metadata": {
        "id": "qLIDMOUMMUPM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "KU3JwItcMWaX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VggFeatures(nn.Module):\n",
        "    def __init__(self, drop=0.2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1a = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv1b = nn.Conv2d(64, out_channels=64, kernel_size=3, padding=1)\n",
        "\n",
        "        self.conv2a = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.conv2b = nn.Conv2d(128, 128, 3, padding=1)\n",
        "\n",
        "        self.conv3a = nn.Conv2d(128, 256, 3, padding=1)\n",
        "        self.conv3b = nn.Conv2d(256, 256, 3, padding=1)\n",
        "\n",
        "        self.conv4a = nn.Conv2d(256, 512, 3, padding=1)\n",
        "        self.conv4b = nn.Conv2d(512, 512, 3, padding=1)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.bn1a = nn.BatchNorm2d(64)\n",
        "        self.bn1b = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.bn2a = nn.BatchNorm2d(128)\n",
        "        self.bn2b = nn.BatchNorm2d(128)\n",
        "\n",
        "        self.bn3a = nn.BatchNorm2d(256)\n",
        "        self.bn3b = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.bn4a = nn.BatchNorm2d(512)\n",
        "        self.bn4b = nn.BatchNorm2d(512)\n",
        "\n",
        "        self.lin1 = nn.Linear(512 * 2 * 2, 4096)\n",
        "        self.lin2 = nn.Linear(4096, 4096)\n",
        "\n",
        "        self.drop = nn.Dropout(p=drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1a(self.conv1a(x)))\n",
        "        x = F.relu(self.bn1b(self.conv1b(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.bn2a(self.conv2a(x)))\n",
        "        x = F.relu(self.bn2b(self.conv2b(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.bn3a(self.conv3a(x)))\n",
        "        x = F.relu(self.bn3b(self.conv3b(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = F.relu(self.bn4a(self.conv4a(x)))\n",
        "        x = F.relu(self.bn4b(self.conv4b(x)))\n",
        "        x = self.pool(x)\n",
        "        # print(x.shape)\n",
        "\n",
        "        x = x.view(-1, 512 * 2 * 2)\n",
        "        x = F.relu(self.drop(self.lin1(x)))\n",
        "        x = F.relu(self.drop(self.lin2(x)))\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Vgg(VggFeatures):\n",
        "    def __init__(self, drop=0.2):\n",
        "        super().__init__(drop)\n",
        "        self.lin3 = nn.Linear(4096, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = super().forward(x)\n",
        "        x = self.lin3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "OiS3hEEFMX-p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "class TestingDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.names = []\n",
        "\n",
        "        self.images = sorted(glob.glob(f\"{self.img_dir}/*\"))\n",
        "        self.names = [os.path.basename(image)[:-4] for image in self.images]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getnames__(self):\n",
        "        return self.names\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.images[idx]).convert(\"L\")\n",
        "        image = self.transform(image)\n",
        "        return image, self.names[idx]"
      ],
      "metadata": {
        "id": "BUqwROMrMaKW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "mu, st = 0, 255"
      ],
      "metadata": {
        "id": "dohLsSl1McaW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.TenCrop(40),\n",
        "    transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "    transforms.Lambda(lambda tensors: torch.stack([transforms.Normalize(mean=(mu,), std=(st,))(t) for t in tensors])),\n",
        "])"
      ],
      "metadata": {
        "id": "brTqTKDAMcpS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = TestingDataset(f\"{unzip_path}/data/Images/test\", test_transform)\n",
        "print(f\"Total testing data: {test_data.__len__()}\")\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgRvORX2Mdr_",
        "outputId": "48070562-4270-4918-bfdf-17f9645755b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total testing data: 3589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 載入 checkpoint\n",
        "checkpoint = torch.load('/content/drive/MyDrive/ML/epoch_96')\n",
        "# if using CPU:\n",
        "# checkpoint = torch.load('/content/drive/MyDrive/ML/epoch_96', map_location=torch.device('cpu'))\n",
        "net = Vgg().to(device)\n",
        "net.load_state_dict(checkpoint[\"params\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdnCisACMe3V",
        "outputId": "466ba61b-7b10-4f43-d356-dd05b63c238d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def evaluate_and_save_csv(net, dataloader, index_mapping, output_csv_path):\n",
        "    net = net.eval()\n",
        "    predictions = []\n",
        "    filenames = []  # 用於儲存檔案名稱\n",
        "\n",
        "    # 建立索引到類別名稱的映射\n",
        "\n",
        "    class_dic = {v: k for k, v in index_mapping.items()}\n",
        "    reverse_index_mapping = {k: v for v, k in index_mapping.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, filepaths in dataloader:\n",
        "            images = images.to(device)\n",
        "\n",
        "            bs, ncrops, c, h, w = images.shape\n",
        "            images = images.view(-1, c, h, w)\n",
        "\n",
        "            # 模型前向傳播\n",
        "            outputs = net(images)\n",
        "            # combine results across the crops\n",
        "            outputs = outputs.view(bs, ncrops, -1)\n",
        "            outputs = torch.sum(outputs, dim=1) / ncrops\n",
        "            preds = outputs.argmax(dim=-1).cpu().numpy().tolist()\n",
        "\n",
        "            # 添加檔案名稱和預測結果\n",
        "            filenames.extend(filepaths)\n",
        "            predictions.extend(preds)\n",
        "\n",
        "    # 建立 DataFrame 並保存為 CSV\n",
        "    submission = pd.DataFrame({\"filename\": filenames, \"label\": predictions})\n",
        "    submission.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Predictions saved to {output_csv_path}\")"
      ],
      "metadata": {
        "id": "_4UfyPWYMggY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_mapping = {\"Angry\": 0, \"Disgust\": 1, \"Fear\": 2, \"Happy\": 3, \"Neutral\": 4, \"Sad\": 5, \"Surprise\": 6}\n",
        "output_csv_path = \"/content/drive/MyDrive/ML/paper_VGG_96.csv\"\n",
        "\n",
        "evaluate_and_save_csv(net, test_loader, index_mapping, output_csv_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sik6uxxMh3z",
        "outputId": "382f453f-c3c4-4c49-83d2-acf60085c30d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to /content/drive/MyDrive/ML/paper_VGG_96_test.csv\n"
          ]
        }
      ]
    }
  ]
}